{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "fruit_predictor.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wR934F-o2F-G"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS3zsu_-F2Yp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a02597-9a02-4adb-d73a-60d127d5d216"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dH8o7an2F-I"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdAZZANt2F-K"
      },
      "source": [
        "model=Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haERduSp2F-L"
      },
      "source": [
        "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lu0UBS52F-L"
      },
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLM-xxXg2F-L"
      },
      "source": [
        "#input layer \n",
        "model.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgLNGuNj2F-M"
      },
      "source": [
        "#hidden layer\n",
        "model.add(Dense(units=128,activation=\"relu\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul5aGhCm2F-M"
      },
      "source": [
        "#output layer\n",
        "model.add(Dense(units=4,activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMs8PTYO2F-N"
      },
      "source": [
        "# Preprocessing image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJVmttzJ2F-N"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN8l1FZ-2F-N"
      },
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbGn3Uto2F-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfd14d61-3256-462d-8601-13b4eb4f9ce8"
      },
      "source": [
        "x_train=train_datagen.flow_from_directory(\"/content/gdrive/MyDrive/nutrition analysis2/final_dataset/trainset\",target_size=(64,64),batch_size=32,class_mode=\"categorical\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 279 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYYIjC1y2F-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5121a0ff-1b64-4cc2-a47f-84462e873157"
      },
      "source": [
        "print(x_train.class_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'apple': 0, 'banana': 1, 'mango': 2, 'orange': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8neY59282F-O"
      },
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2huMyI-52F-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d347bd-b947-4cfd-8ed6-29da683ed9b7"
      },
      "source": [
        "x_test=test_datagen.flow_from_directory(\"/content/gdrive/MyDrive/nutrition analysis2/final_dataset/testset\",target_size=(64,64),batch_size=32,class_mode=\"categorical\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 120 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0AptAAG2F-P"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCRQJEma2F-Q"
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cZrEGnN2F-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b973c34b-afbd-4369-97c4-b4175a7eed91"
      },
      "source": [
        "#steps per epoch=279/30;validation_step=120/30\n",
        "model.fit_generator(x_train,steps_per_epoch=9,epochs=30,validation_data=x_test,validation_steps=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 104s 12s/step - loss: 5.5771 - accuracy: 0.2939 - val_loss: 3.2693 - val_accuracy: 0.2667\n",
            "Epoch 2/30\n",
            "9/9 [==============================] - 4s 451ms/step - loss: 1.6199 - accuracy: 0.3978 - val_loss: 1.1770 - val_accuracy: 0.5333\n",
            "Epoch 3/30\n",
            "9/9 [==============================] - 4s 462ms/step - loss: 0.9986 - accuracy: 0.5376 - val_loss: 1.0005 - val_accuracy: 0.5667\n",
            "Epoch 4/30\n",
            "9/9 [==============================] - 4s 475ms/step - loss: 0.8544 - accuracy: 0.6272 - val_loss: 1.0398 - val_accuracy: 0.5167\n",
            "Epoch 5/30\n",
            "9/9 [==============================] - 4s 467ms/step - loss: 0.7648 - accuracy: 0.6595 - val_loss: 1.0043 - val_accuracy: 0.5667\n",
            "Epoch 6/30\n",
            "9/9 [==============================] - 4s 461ms/step - loss: 0.6243 - accuracy: 0.7204 - val_loss: 0.9230 - val_accuracy: 0.6250\n",
            "Epoch 7/30\n",
            "9/9 [==============================] - 4s 472ms/step - loss: 0.5913 - accuracy: 0.7312 - val_loss: 1.0235 - val_accuracy: 0.5917\n",
            "Epoch 8/30\n",
            "9/9 [==============================] - 4s 467ms/step - loss: 0.5753 - accuracy: 0.7670 - val_loss: 1.0115 - val_accuracy: 0.6167\n",
            "Epoch 9/30\n",
            "9/9 [==============================] - 4s 447ms/step - loss: 0.5696 - accuracy: 0.7348 - val_loss: 0.9080 - val_accuracy: 0.6500\n",
            "Epoch 10/30\n",
            "9/9 [==============================] - 4s 456ms/step - loss: 0.5477 - accuracy: 0.7455 - val_loss: 0.9480 - val_accuracy: 0.6083\n",
            "Epoch 11/30\n",
            "9/9 [==============================] - 4s 444ms/step - loss: 0.5248 - accuracy: 0.7814 - val_loss: 0.9433 - val_accuracy: 0.6000\n",
            "Epoch 12/30\n",
            "9/9 [==============================] - 4s 444ms/step - loss: 0.5553 - accuracy: 0.7455 - val_loss: 1.0307 - val_accuracy: 0.6333\n",
            "Epoch 13/30\n",
            "9/9 [==============================] - 4s 474ms/step - loss: 0.5058 - accuracy: 0.7491 - val_loss: 0.9959 - val_accuracy: 0.6250\n",
            "Epoch 14/30\n",
            "9/9 [==============================] - 4s 452ms/step - loss: 0.4706 - accuracy: 0.8100 - val_loss: 0.9199 - val_accuracy: 0.6417\n",
            "Epoch 15/30\n",
            "9/9 [==============================] - 4s 447ms/step - loss: 0.4256 - accuracy: 0.8244 - val_loss: 1.0072 - val_accuracy: 0.5750\n",
            "Epoch 16/30\n",
            "9/9 [==============================] - 4s 457ms/step - loss: 0.4060 - accuracy: 0.8315 - val_loss: 1.0087 - val_accuracy: 0.5917\n",
            "Epoch 17/30\n",
            "9/9 [==============================] - 4s 457ms/step - loss: 0.3978 - accuracy: 0.8351 - val_loss: 0.9985 - val_accuracy: 0.6333\n",
            "Epoch 18/30\n",
            "9/9 [==============================] - 4s 449ms/step - loss: 0.4130 - accuracy: 0.8208 - val_loss: 0.9933 - val_accuracy: 0.6333\n",
            "Epoch 19/30\n",
            "9/9 [==============================] - 4s 457ms/step - loss: 0.3797 - accuracy: 0.8530 - val_loss: 0.9963 - val_accuracy: 0.6250\n",
            "Epoch 20/30\n",
            "9/9 [==============================] - 4s 440ms/step - loss: 0.3446 - accuracy: 0.8781 - val_loss: 1.0379 - val_accuracy: 0.6250\n",
            "Epoch 21/30\n",
            "9/9 [==============================] - 4s 448ms/step - loss: 0.3590 - accuracy: 0.8638 - val_loss: 0.9758 - val_accuracy: 0.6250\n",
            "Epoch 22/30\n",
            "9/9 [==============================] - 4s 453ms/step - loss: 0.2985 - accuracy: 0.9104 - val_loss: 1.0679 - val_accuracy: 0.6250\n",
            "Epoch 23/30\n",
            "9/9 [==============================] - 4s 452ms/step - loss: 0.3326 - accuracy: 0.8853 - val_loss: 1.0759 - val_accuracy: 0.6667\n",
            "Epoch 24/30\n",
            "9/9 [==============================] - 4s 459ms/step - loss: 0.3043 - accuracy: 0.8853 - val_loss: 0.9839 - val_accuracy: 0.6417\n",
            "Epoch 25/30\n",
            "9/9 [==============================] - 4s 453ms/step - loss: 0.2966 - accuracy: 0.9104 - val_loss: 1.0358 - val_accuracy: 0.6333\n",
            "Epoch 26/30\n",
            "9/9 [==============================] - 4s 442ms/step - loss: 0.2746 - accuracy: 0.9140 - val_loss: 1.0778 - val_accuracy: 0.6500\n",
            "Epoch 27/30\n",
            "9/9 [==============================] - 4s 446ms/step - loss: 0.2336 - accuracy: 0.9391 - val_loss: 1.2030 - val_accuracy: 0.6250\n",
            "Epoch 28/30\n",
            "9/9 [==============================] - 4s 441ms/step - loss: 0.2012 - accuracy: 0.9427 - val_loss: 1.1057 - val_accuracy: 0.6167\n",
            "Epoch 29/30\n",
            "9/9 [==============================] - 4s 460ms/step - loss: 0.2327 - accuracy: 0.9140 - val_loss: 1.0663 - val_accuracy: 0.6083\n",
            "Epoch 30/30\n",
            "9/9 [==============================] - 4s 459ms/step - loss: 0.2324 - accuracy: 0.9176 - val_loss: 1.2275 - val_accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f201fd3b290>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXcZyDgN2F-R"
      },
      "source": [
        "model.save(\"fruit_predict.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMTtAJYa2F-R"
      },
      "source": [
        "#working fine# [update-GN 04:42]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}